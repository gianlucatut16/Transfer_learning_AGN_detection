{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gltut\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.utils.io import capture_output\n",
    "\n",
    "import efficientnet_pytorch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler(object):\n",
    "    def __init__(self, min_val=0.0, max_val=1.0):\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        min_tensor = torch.min(tensor)\n",
    "        max_tensor = torch.max(tensor)\n",
    "        \n",
    "        if min_tensor == max_tensor:\n",
    "            # All pixels have the same value, return a tensor filled with min_val\n",
    "            return torch.full_like(tensor, self.min_val)\n",
    "        \n",
    "        scaled_tensor = (tensor - min_tensor) / (max_tensor - min_tensor)  # Scale to [0, 1]\n",
    "        scaled_tensor = scaled_tensor * (self.max_val - self.min_val) + self.min_val  # Scale to [min_val, max_val]\n",
    "        return scaled_tensor\n",
    "    \n",
    "# # Define the transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    MinMaxScaler(min_val=0.0, max_val=1.0),\n",
    "])\n",
    "\n",
    "\n",
    "class NumpyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        if self.transform:\n",
    "            x = Image.fromarray(x.astype(np.uint8))\n",
    "            x = self.transform(x)\n",
    "        return x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_latent_vectors(network, train_loader, device):\n",
    "    network.eval()\n",
    "    latent_vectors = []\n",
    "    for cnt, x in enumerate(train_loader):\n",
    "        x = x.to(device) \n",
    "        latent_vectors.append(network.extract_features(x).mean(dim=(2,3)))\n",
    "    latent_vectors = torch.cat(latent_vectors).cpu().numpy()\n",
    "    return latent_vectors  \n",
    "\n",
    "def blockPrinting(func):\n",
    "    def func_wrapper(*args, **kwargs):\n",
    "        with capture_output():\n",
    "            value = func(*args, **kwargs)\n",
    "        return value\n",
    "    return func_wrapper\n",
    "\n",
    "\n",
    "@blockPrinting\n",
    "def get_features(loader):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    network = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    network.to(device)\n",
    "    network.eval()\n",
    "    features = get_latent_vectors(network, loader, device)\n",
    "    return features\n",
    "\n",
    "def get_nns(query, neigh):\n",
    "    res = neigh.kneighbors(query)\n",
    "    similar = res[1][0]\n",
    "    dists = res[0][0]\n",
    "    return similar, dists\n",
    "\n",
    "\n",
    "def cut_imgs(img):\n",
    "    new_shape = 21\n",
    "\n",
    "    # Plot + colorbar\n",
    "    start_index = (img.shape[0] - new_shape) // 2\n",
    "    sub_array = img[start_index:start_index+new_shape, start_index:start_index+new_shape]\n",
    "    return sub_array\n",
    "\n",
    "def norm_imgs(column):\n",
    "    size = 21\n",
    "    test_imgs = df[column]\n",
    "    images = np.zeros((len(test_imgs), size , size,3), dtype= np.float32)\n",
    "\n",
    "    for i in range(len(test_imgs)):\n",
    "        img = test_imgs[i]\n",
    "        img = Image.fromarray(img).convert('RGB')D\n",
    "        img= np.array(img)          \n",
    "        images[i]=img\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def get_classification(values):\n",
    "\n",
    "    votes_agn, votes_noagn = 0, 0\n",
    "    for x in values[1:]:\n",
    "        if x < 677:\n",
    "            votes_agn += 1\n",
    "        else:\n",
    "            votes_noagn += 1\n",
    "    \n",
    "    if votes_agn > votes_noagn:\n",
    "        classification = True\n",
    "    else:\n",
    "        classification = False\n",
    "\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('true_df_21.pkl', 'rb') as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Removing all the columns useless according to feature importance...')\n",
    "\n",
    "important_columns = ['Freq1_harmonics_amplitude_0', 'Freq1_harmonics_amplitude_1']\n",
    "\n",
    "df = df[important_columns + ['AGN']]\n",
    "\n",
    "print('Melting the dataset in order to have a data augmentation')\n",
    "df = df.melt(id_vars='AGN', value_vars=df.columns.values[: -1], var_name='variable', value_name='cutout')\n",
    "\n",
    "print('Normalize images...')\n",
    "images = norm_imgs('cutout')\n",
    "dataset = NumpyDataset(images, transform = transform)\n",
    "\n",
    "\n",
    "if \"linux\" in sys.platform:\n",
    "    nw=torch.get_num_threads()-1\n",
    "else:\n",
    "    nw=0\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=False, num_workers=nw)\n",
    "\n",
    "\n",
    "\n",
    "def get_classification_and_probs(values, neighbors):\n",
    "\n",
    "    votes_agn, votes_noagn = 0, 0\n",
    "    for x in values[1:]:\n",
    "        if x < 677:\n",
    "            votes_agn += 1\n",
    "        else:\n",
    "            votes_noagn += 1\n",
    "\n",
    "    total_neighbors = len(values) - 1\n",
    "\n",
    "    prob_agn = votes_agn/total_neighbors\n",
    "    prob_noagn = votes_noagn/total_neighbors\n",
    "    \n",
    "    if votes_agn > votes_noagn:\n",
    "        classification = True\n",
    "    else:\n",
    "        classification = False\n",
    "\n",
    "    return prob_agn, prob_noagn, classification\n",
    "\n",
    "print('Getting features from Efficient-net...')\n",
    "features = get_features(loader)\n",
    "\n",
    "print('Running Nearest Neighbors...')\n",
    "neigh = NearestNeighbors(n_neighbors=16)\n",
    "neigh.fit(features)\n",
    "\n",
    "print('Taking votes...')\n",
    "preds = []\n",
    "for indice in range(features.shape[0]):\n",
    "    query_features = features[indice].reshape(1, -1)\n",
    "    similar, dists = get_nns(query_features, neigh)\n",
    "    preds.append(get_classification(similar))\n",
    "    if indice % 100:\n",
    "        print(indice)\n",
    "\n",
    "y_pred = [x[2] for x in preds]\n",
    "print(classification_report(df['AGN'], y_pred))\n",
    "\n",
    "sns.heatmap(confusion_matrix(df['AGN'], y_pred), annot = True, cmap = 'Blues', fmt = '.6g')\n",
    "plt.savefig('Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
